{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (21.3.1)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (1.10.0)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.21.4-cp39-cp39-macosx_10_9_x86_64.whl (17.0 MB)\n",
      "     |████████████████████████████████| 17.0 MB 893 kB/s            \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch) (4.0.1)\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.21.4\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pip\n",
    "!pip install torch numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from functools import partial\n",
    "from dataclasses import dataclass\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2dAuto(nn.Conv2d):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.padding = (self.kernel_size[0] // 2, self.kernel_size[1] // 2) # dynamic add padding based on the kernel_size\n",
    "\n",
    "        # Draw this out on a conv layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv3x3 = partial(Conv2dAuto, kernel_size=3, bias=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = conv3x3(1,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = conv3x3(1,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "           1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "           1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "           1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "           1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "           1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "           1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "           1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "           1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "           1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "           1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "           1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "           1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "           1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "           1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "           1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "           1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "           1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "           1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "           1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "           1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "           1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "           1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "           1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "           1., 1., 1., 1., 1., 1., 1.]]]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(np.ones([1,1,24,24]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0107,  0.2835,  0.2835,  ...,  0.2835,  0.2835,  0.0433],\n",
       "          [-0.0122,  0.5976,  0.5976,  ...,  0.5976,  0.5976,  0.1302],\n",
       "          [-0.0122,  0.5976,  0.5976,  ...,  0.5976,  0.5976,  0.1302],\n",
       "          ...,\n",
       "          [-0.0122,  0.5976,  0.5976,  ...,  0.5976,  0.5976,  0.1302],\n",
       "          [-0.0122,  0.5976,  0.5976,  ...,  0.5976,  0.5976,  0.1302],\n",
       "          [ 0.0730,  0.4474,  0.4474,  ...,  0.4474,  0.4474,  0.0558]],\n",
       "\n",
       "         [[ 0.1568,  0.0384,  0.0384,  ...,  0.0384,  0.0384, -0.3537],\n",
       "          [ 0.1874,  0.1528,  0.1528,  ...,  0.1528,  0.1528, -0.0078],\n",
       "          [ 0.1874,  0.1528,  0.1528,  ...,  0.1528,  0.1528, -0.0078],\n",
       "          ...,\n",
       "          [ 0.1874,  0.1528,  0.1528,  ...,  0.1528,  0.1528, -0.0078],\n",
       "          [ 0.1874,  0.1528,  0.1528,  ...,  0.1528,  0.1528, -0.0078],\n",
       "          [ 0.0311,  0.2231,  0.2231,  ...,  0.2231,  0.2231,  0.1694]],\n",
       "\n",
       "         [[-0.7014, -0.5925, -0.5925,  ..., -0.5925, -0.5925, -0.2795],\n",
       "          [-0.9639, -0.7053, -0.7053,  ..., -0.7053, -0.7053, -0.2462],\n",
       "          [-0.9639, -0.7053, -0.7053,  ..., -0.7053, -0.7053, -0.2462],\n",
       "          ...,\n",
       "          [-0.9639, -0.7053, -0.7053,  ..., -0.7053, -0.7053, -0.2462],\n",
       "          [-0.9639, -0.7053, -0.7053,  ..., -0.7053, -0.7053, -0.2462],\n",
       "          [-0.7249, -0.3997, -0.3997,  ..., -0.3997, -0.3997, -0.0734]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.1646, -0.4832, -0.4832,  ..., -0.4832, -0.4832, -0.5553],\n",
       "          [-0.1333, -0.4117, -0.4117,  ..., -0.4117, -0.4117, -0.2010],\n",
       "          [-0.1333, -0.4117, -0.4117,  ..., -0.4117, -0.4117, -0.2010],\n",
       "          ...,\n",
       "          [-0.1333, -0.4117, -0.4117,  ..., -0.4117, -0.4117, -0.2010],\n",
       "          [-0.1333, -0.4117, -0.4117,  ..., -0.4117, -0.4117, -0.2010],\n",
       "          [-0.1030, -0.3863, -0.3863,  ..., -0.3863, -0.3863,  0.0265]],\n",
       "\n",
       "         [[ 0.7455,  0.5005,  0.5005,  ...,  0.5005,  0.5005,  0.1933],\n",
       "          [ 0.7028,  0.5880,  0.5880,  ...,  0.5880,  0.5880,  0.2342],\n",
       "          [ 0.7028,  0.5880,  0.5880,  ...,  0.5880,  0.5880,  0.2342],\n",
       "          ...,\n",
       "          [ 0.7028,  0.5880,  0.5880,  ...,  0.5880,  0.5880,  0.2342],\n",
       "          [ 0.7028,  0.5880,  0.5880,  ...,  0.5880,  0.5880,  0.2342],\n",
       "          [ 0.4434,  0.3917,  0.3917,  ...,  0.3917,  0.3917,  0.1921]],\n",
       "\n",
       "         [[ 0.0567,  0.0823,  0.0823,  ...,  0.0823,  0.0823,  0.1695],\n",
       "          [ 0.5684,  0.6956,  0.6956,  ...,  0.6956,  0.6956,  0.5564],\n",
       "          [ 0.5684,  0.6956,  0.6956,  ...,  0.6956,  0.6956,  0.5564],\n",
       "          ...,\n",
       "          [ 0.5684,  0.6956,  0.6956,  ...,  0.6956,  0.6956,  0.5564],\n",
       "          [ 0.5684,  0.6956,  0.6956,  ...,  0.6956,  0.6956,  0.5564],\n",
       "          [ 0.5222,  0.8586,  0.8586,  ...,  0.8586,  0.8586,  0.6924]]]],\n",
       "       grad_fn=<ThnnConv2DBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a(torch.tensor(np.ones([1,1,24,24])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.4364,  0.5427,  0.5427,  ...,  0.5427,  0.5427,  0.2737],\n",
       "          [ 0.5661,  0.8077,  0.8077,  ...,  0.8077,  0.8077,  0.5807],\n",
       "          [ 0.5661,  0.8077,  0.8077,  ...,  0.8077,  0.8077,  0.5807],\n",
       "          ...,\n",
       "          [ 0.5661,  0.8077,  0.8077,  ...,  0.8077,  0.8077,  0.5807],\n",
       "          [ 0.5661,  0.8077,  0.8077,  ...,  0.8077,  0.8077,  0.5807],\n",
       "          [ 0.2787,  0.5318,  0.5318,  ...,  0.5318,  0.5318,  0.6234]],\n",
       "\n",
       "         [[-0.0129,  0.0519,  0.0519,  ...,  0.0519,  0.0519,  0.2116],\n",
       "          [-0.3122, -0.5632, -0.5632,  ..., -0.5632, -0.5632, -0.1168],\n",
       "          [-0.3122, -0.5632, -0.5632,  ..., -0.5632, -0.5632, -0.1168],\n",
       "          ...,\n",
       "          [-0.3122, -0.5632, -0.5632,  ..., -0.5632, -0.5632, -0.1168],\n",
       "          [-0.3122, -0.5632, -0.5632,  ..., -0.5632, -0.5632, -0.1168],\n",
       "          [-0.0160, -0.2755, -0.2755,  ..., -0.2755, -0.2755, -0.1030]],\n",
       "\n",
       "         [[ 0.0988, -0.0991, -0.0991,  ..., -0.0991, -0.0991,  0.1296],\n",
       "          [-0.0297, -0.2281, -0.2281,  ..., -0.2281, -0.2281, -0.1825],\n",
       "          [-0.0297, -0.2281, -0.2281,  ..., -0.2281, -0.2281, -0.1825],\n",
       "          ...,\n",
       "          [-0.0297, -0.2281, -0.2281,  ..., -0.2281, -0.2281, -0.1825],\n",
       "          [-0.0297, -0.2281, -0.2281,  ..., -0.2281, -0.2281, -0.1825],\n",
       "          [-0.1282, -0.3377, -0.3377,  ..., -0.3377, -0.3377, -0.4633]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0358, -0.5782, -0.5782,  ..., -0.5782, -0.5782, -0.6125],\n",
       "          [ 0.0616, -0.7482, -0.7482,  ..., -0.7482, -0.7482, -0.8570],\n",
       "          [ 0.0616, -0.7482, -0.7482,  ..., -0.7482, -0.7482, -0.8570],\n",
       "          ...,\n",
       "          [ 0.0616, -0.7482, -0.7482,  ..., -0.7482, -0.7482, -0.8570],\n",
       "          [ 0.0616, -0.7482, -0.7482,  ..., -0.7482, -0.7482, -0.8570],\n",
       "          [ 0.2277, -0.3532, -0.3532,  ..., -0.3532, -0.3532, -0.4188]],\n",
       "\n",
       "         [[ 0.5644,  0.5615,  0.5615,  ...,  0.5615,  0.5615,  0.1140],\n",
       "          [ 0.2406,  0.3216,  0.3216,  ...,  0.3216,  0.3216,  0.1170],\n",
       "          [ 0.2406,  0.3216,  0.3216,  ...,  0.3216,  0.3216,  0.1170],\n",
       "          ...,\n",
       "          [ 0.2406,  0.3216,  0.3216,  ...,  0.3216,  0.3216,  0.1170],\n",
       "          [ 0.2406,  0.3216,  0.3216,  ...,  0.3216,  0.3216,  0.1170],\n",
       "          [-0.2528, -0.0376, -0.0376,  ..., -0.0376, -0.0376,  0.0678]],\n",
       "\n",
       "         [[ 0.2892,  0.0034,  0.0034,  ...,  0.0034,  0.0034, -0.0519],\n",
       "          [ 0.7420,  0.1276,  0.1276,  ...,  0.1276,  0.1276, -0.2246],\n",
       "          [ 0.7420,  0.1276,  0.1276,  ...,  0.1276,  0.1276, -0.2246],\n",
       "          ...,\n",
       "          [ 0.7420,  0.1276,  0.1276,  ...,  0.1276,  0.1276, -0.2246],\n",
       "          [ 0.7420,  0.1276,  0.1276,  ...,  0.1276,  0.1276, -0.2246],\n",
       "          [ 0.7005,  0.0603,  0.0603,  ...,  0.0603,  0.0603, -0.4036]]]],\n",
       "       grad_fn=<ThnnConv2DBackward0>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b(torch.tensor(np.ones([1,1,24,24])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2dAuto(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n"
     ]
    }
   ],
   "source": [
    "conv = conv3x3(in_channels=32, out_channels=64)\n",
    "print(conv)\n",
    "del conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.in_channels, self.out_channels =  in_channels, out_channels\n",
    "        self.blocks = nn.Identity()\n",
    "        self.shortcut = nn.Identity()   \n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        if self.should_apply_shortcut: residual = self.shortcut(x)\n",
    "        x = self.blocks(x)\n",
    "        x += residual\n",
    "        return x\n",
    "    \n",
    "    @property\n",
    "    def should_apply_shortcut(self):\n",
    "        return self.in_channels != self.out_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResidualBlock(32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[2.]]]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = torch.ones((1, 1, 1, 1))\n",
    "\n",
    "block = ResidualBlock(1, 64)\n",
    "block(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class ResNetResidualBlock(ResidualBlock):\n",
    "    def __init__(self, in_channels, out_channels, expansion=1, downsampling=1, conv=conv3x3, *args, **kwargs):\n",
    "        super().__init__(in_channels, out_channels)\n",
    "        self.expansion, self.downsampling, self.conv = expansion, downsampling, conv\n",
    "        self.shortcut = nn.Sequential(OrderedDict(\n",
    "        {\n",
    "            'conv' : nn.Conv2d(self.in_channels, self.expanded_channels, kernel_size=1,\n",
    "                      stride=self.downsampling, bias=False),\n",
    "            'bn' : nn.BatchNorm2d(self.expanded_channels)\n",
    "            \n",
    "        })) if self.should_apply_shortcut else None\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def expanded_channels(self):\n",
    "        return self.out_channels * self.expansion\n",
    "    \n",
    "    @property\n",
    "    def should_apply_shortcut(self):\n",
    "        return self.in_channels != self.expanded_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = ResNetResidualBlock(4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "def conv_bn(in_channels, out_channels, conv, *args, **kwargs):\n",
    "    return nn.Sequential(OrderedDict({'conv': conv(in_channels, out_channels, *args, **kwargs), \n",
    "                          'bn': nn.BatchNorm2d(out_channels) }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_bn(3, 3, nn.Conv2d, kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBasicBlock(ResNetResidualBlock):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, out_channels, activation=nn.ReLU, *args, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, *args, **kwargs)\n",
    "        self.blocks = nn.Sequential(\n",
    "            conv_bn(self.in_channels, self.out_channels, conv=self.conv, bias=False, stride=self.downsampling),\n",
    "            activation(),\n",
    "            conv_bn(self.out_channels, self.expanded_channels, conv=self.conv, bias=False),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 224, 224])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block(dummy).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 3.4367e+00,  3.6397e+00,  7.8945e-01,  ...,  7.8945e-01,\n",
       "           -2.1659e-01, -1.1817e+01],\n",
       "          [-1.0512e+01, -8.3684e+00, -9.3123e+00,  ..., -9.3123e+00,\n",
       "           -3.0347e+00, -8.5658e+00],\n",
       "          [-4.7239e+00,  1.7738e-01,  9.3146e-02,  ...,  9.3146e-02,\n",
       "            2.3099e+00, -5.3576e+00],\n",
       "          ...,\n",
       "          [-4.7239e+00,  1.7738e-01,  9.3146e-02,  ...,  9.3146e-02,\n",
       "            2.3099e+00, -5.3576e+00],\n",
       "          [-2.7987e-01,  4.5152e+00,  3.9055e+00,  ...,  3.9055e+00,\n",
       "            1.7787e+00, -2.5194e+00],\n",
       "          [-7.6404e+00, -8.8866e+00, -8.0001e+00,  ..., -8.0001e+00,\n",
       "           -9.1045e+00, -4.1347e+00]],\n",
       "\n",
       "         [[ 6.5132e+00,  9.3447e+00,  3.0498e+00,  ...,  3.0498e+00,\n",
       "            3.5772e+00,  4.0905e+00],\n",
       "          [ 4.7000e-01, -4.1295e-01, -4.6543e+00,  ..., -4.6543e+00,\n",
       "           -1.0463e+01, -5.0076e+00],\n",
       "          [ 4.7638e+00,  2.1124e+00,  2.9177e-02,  ...,  2.9177e-02,\n",
       "           -3.0361e+00,  2.5984e+00],\n",
       "          ...,\n",
       "          [ 4.7638e+00,  2.1124e+00,  2.9177e-02,  ...,  2.9177e-02,\n",
       "           -3.0361e+00,  2.5984e+00],\n",
       "          [ 2.8027e-01,  2.3057e+00,  1.0542e+00,  ...,  1.0542e+00,\n",
       "           -4.1172e-01,  6.5567e+00],\n",
       "          [-8.3547e+00, -1.3848e+01, -1.2216e+01,  ..., -1.2216e+01,\n",
       "           -1.1804e+01, -2.9278e+00]],\n",
       "\n",
       "         [[ 3.7639e+00,  1.0401e-01,  4.9422e+00,  ...,  4.9422e+00,\n",
       "            8.2703e+00,  2.6342e+00],\n",
       "          [ 7.5088e+00, -4.0485e+00,  4.6505e+00,  ...,  4.6505e+00,\n",
       "            8.6359e+00,  4.6637e+00],\n",
       "          [ 8.7020e+00, -7.1937e+00, -8.6168e-02,  ..., -8.6168e-02,\n",
       "            5.4773e+00,  4.2244e+00],\n",
       "          ...,\n",
       "          [ 8.7020e+00, -7.1937e+00, -8.6168e-02,  ..., -8.6168e-02,\n",
       "            5.4773e+00,  4.2244e+00],\n",
       "          [ 1.0942e+01, -2.3989e+00, -1.4726e+00,  ..., -1.4726e+00,\n",
       "            2.4388e+00, -1.7678e+00],\n",
       "          [ 6.6825e+00, -3.7709e+00, -6.3165e-01,  ..., -6.3165e-01,\n",
       "            4.9675e+00,  8.2728e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 6.1990e+00, -4.7633e+00, -7.9985e-01,  ..., -7.9985e-01,\n",
       "           -6.1888e-01, -8.0155e+00],\n",
       "          [-3.6883e-02, -1.1398e+01, -3.5978e+00,  ..., -3.5978e+00,\n",
       "           -3.2623e+00, -2.2406e+00],\n",
       "          [ 4.9246e+00, -8.8894e+00,  3.2183e-02,  ...,  3.2183e-02,\n",
       "           -3.8793e+00, -5.6142e+00],\n",
       "          ...,\n",
       "          [ 4.9246e+00, -8.8894e+00,  3.2183e-02,  ...,  3.2183e-02,\n",
       "           -3.8793e+00, -5.6142e+00],\n",
       "          [ 7.0828e+00, -6.1892e+00,  4.4423e+00,  ...,  4.4423e+00,\n",
       "           -1.8530e-01, -4.5824e+00],\n",
       "          [ 1.4171e+01,  4.0342e+00,  6.4347e+00,  ...,  6.4347e+00,\n",
       "           -1.7320e+00, -1.0775e+01]],\n",
       "\n",
       "         [[ 5.6718e+00, -1.4634e+00,  1.5028e+00,  ...,  1.5028e+00,\n",
       "           -2.9342e+00,  1.8980e+00],\n",
       "          [ 8.6129e-01, -1.1262e+01, -1.0002e+01,  ..., -1.0002e+01,\n",
       "           -1.2762e+01, -6.4509e+00],\n",
       "          [ 6.5986e+00, -2.9337e+00,  8.4252e-02,  ...,  8.4252e-02,\n",
       "           -4.3113e+00, -3.4951e+00],\n",
       "          ...,\n",
       "          [ 6.5986e+00, -2.9337e+00,  8.4252e-02,  ...,  8.4252e-02,\n",
       "           -4.3113e+00, -3.4951e+00],\n",
       "          [ 5.7527e+00, -7.2548e+00, -6.1381e+00,  ..., -6.1381e+00,\n",
       "           -1.1665e+01, -1.0377e+01],\n",
       "          [ 2.7249e+00,  1.7316e+00,  4.7368e-01,  ...,  4.7368e-01,\n",
       "           -7.5338e-01, -4.5024e+00]],\n",
       "\n",
       "         [[ 5.9790e-01, -4.6749e+00,  1.4823e+00,  ...,  1.4823e+00,\n",
       "           -4.9987e+00, -4.4164e-01],\n",
       "          [-1.4178e+00, -6.3580e+00,  4.5073e+00,  ...,  4.5073e+00,\n",
       "            5.0825e+00,  1.7191e+00],\n",
       "          [-9.3273e-01, -5.1518e+00,  7.5806e-03,  ...,  7.5806e-03,\n",
       "            9.1839e-01,  1.6609e+00],\n",
       "          ...,\n",
       "          [-9.3273e-01, -5.1518e+00,  7.5806e-03,  ...,  7.5806e-03,\n",
       "            9.1839e-01,  1.6609e+00],\n",
       "          [-1.3048e+00, -1.5193e+01, -1.1077e+01,  ..., -1.1077e+01,\n",
       "           -5.5493e+00, -3.7699e+00],\n",
       "          [ 1.5024e+01,  7.8661e+00,  6.8861e+00,  ...,  6.8861e+00,\n",
       "            1.5341e+01,  6.5116e+00]]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNetBasicBlock(\n",
      "  (blocks): Sequential(\n",
      "    (0): Sequential(\n",
      "      (conv): Conv2dAuto(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): ReLU()\n",
      "    (2): Sequential(\n",
      "      (conv): Conv2dAuto(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (shortcut): Sequential(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "dummy = torch.ones((1, 32, 224, 224))\n",
    "\n",
    "block = ResNetBasicBlock(32, 64)\n",
    "block(dummy).shape\n",
    "print(block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "48c7c8a8c7757d25341c39b998e414ef07b85da09fd1a207738804b669c58fa9"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
